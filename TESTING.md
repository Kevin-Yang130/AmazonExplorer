# Interface Testing
For interface testing, we decided to simply test several random amazon.com and ebay.com product pages, and manually inspect the scraped output with the reviews present on the website. For example, for [this Amazon belt](https://www.amazon.com/Genuine-Leather-Dress-Premium-Quality/dp/B07C25WWS6/?_encoding=UTF8&pd_rd_w=NanEf&content-id=amzn1.sym.255b3518-6e7f-495c-8611-30a58648072e%3Aamzn1.symc.a68f4ca3-28dc-4388-a2cf-24672c480d8f&pf_rd_p=255b3518-6e7f-495c-8611-30a58648072e&pf_rd_r=89RWHZR234823V4TENR4&pd_rd_wg=OHEdc&pd_rd_r=7454b7aa-2d37-4de9-b597-be88681fcbbf&ref_=pd_hp_d_atf_ci_mcx_mr_ca_hp_atf_d&th=1&psc=1), the extension was able to successfully scrape the 13 visible reviews. We also manually cross-checked to verify that the star ratings and content scraped for each of the reviews matched what was visible on the website, which was correct. We repeated this for several other amazon.com and ebay.com product pages.

# Prompt Testing
For the first prompt test, we decided to use the same [Amazon belt](https://www.amazon.com/Genuine-Leather-Dress-Premium-Quality/dp/B07C25WWS6/?_encoding=UTF8&pd_rd_w=NanEf&content-id=amzn1.sym.255b3518-6e7f-495c-8611-30a58648072e%3Aamzn1.symc.a68f4ca3-28dc-4388-a2cf-24672c480d8f&pf_rd_p=255b3518-6e7f-495c-8611-30a58648072e&pf_rd_r=89RWHZR234823V4TENR4&pd_rd_wg=OHEdc&pd_rd_r=7454b7aa-2d37-4de9-b597-be88681fcbbf&ref_=pd_hp_d_atf_ci_mcx_mr_ca_hp_atf_d&th=1&psc=1). The input prompt was "Give me a concise list of pros and cons of this product based on these reviews:", as well as the 13 scraped reviews (title of the review, star ratings, and content). We expected the output to mention the high quality for the price as well as mentions of the leather feel, and also some skepticism about the full durability of the belt, since these were mentioned several times in the review. These points were all included in the final output of our LLM (GPT-4-Turbo), as well as some other points like the comfortable feel and attention to detail of the belt.

For the second prompt test, we decided to use a [watch found on Ebay](https://www.ebay.com/itm/167475764144?_trkparms=amclksrc%3DITM%26aid%3D777008%26algo%3DPERSONAL.TOPIC%26ao%3D1%26asc%3D20230823115209%26meid%3Dd37645be23614137a5244ab8c67aaeaf%26pid%3D101800%26rk%3D1%26rkt%3D1%26itm%3D167475764144%26pmt%3D0%26noa%3D1%26pg%3D4375194%26algv%3DRecentlyViewedItemsV2SignedOut%26brand%3DRolex&_trksid=p4375194.c101800.m5481&_trkparms=parentrq%3A899c4d681960a8808405d65effffc722%7Cpageci%3A7d1f6d71-2631-11f0-8859-32acfacd57e9%7Ciid%3A1%7Cvlpname%3Avlp_homepage). The input prompt was "Give me a concise list of pros and cons of this product based on these reviews:", as well as the scraped reviews from the website. We expected the output to mention things like great communication from the seller, fast shipping, and good condition of the watch. The output of the LLM (GPT-4-Turbo again) included all of these points, as well as extra points like "good value for money" and "accurate product descriptions," which were also found in the reviews later upon manual inspection.

For the third prompt test, we decided to use a [waffle maker found on Amazon](https://www.amazon.com/DECKER-Nonstick-Reversible-Stainless-G48TD/dp/B000063XH7/?th=1). We chose this item because it contained a relatively large number of 1 star reviews, and we were curious whether those comments would be accurately captured in the review summarization. The input prompt was "What are some bad things about this product?", as well as the 9 visible reviews scraped from the website (which we double checked and were accurate). We expected the output to mention things like the dangerous design of the waffle maker as well as quality issues. The output of the LLM (GPT-4-Turbo) included these points, as well as extra points about difficult first-time use and outdated design, which were all in the reviews. 